/* Copyright 2017 The OpenXLA Authors.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
==============================================================================*/

syntax = "proto3";

package zkx;

import "google/protobuf/any.proto";
import "zkx/service/hlo.proto";
import "zkx/zkx_data.proto";

// Proto version of `zkx::CompilationEnvironments`.
message CompilationEnvironmentsProto {
  repeated google.protobuf.Any environments = 1;
}

// Debugging options for ZKX. These options may change at any time - there are
// no guarantees about backward or forward compatibility for these fields.
//
// Debug options naming and organization:
//
// 1. Backend-agnostic options: `zkx_$flag_name` - go first, and sorted
//    alphabetically by the flag name.
//
// 2. Backend-specific options: `zkx_$backend_$flag_name` - must be in the
//    corresponding backend section, and sorted alphabetically by the flag name.
//
message DebugOptions {
  enum LibNvJitLinkMode {
    // LibNvJitLink is used if it is available and no buggy version has been
    // detected.
    LIB_NV_JIT_LINK_MODE_AUTO = 0;
    // LibNvJitLink is never used.
    LIB_NV_JIT_LINK_MODE_DISABLED = 1;
    // LibNvJitLink is used always. If it is not available, compilation will
    // fail.
    LIB_NV_JIT_LINK_MODE_ENABLED = 2;
  }

  // When true, ZKX:CPU uses HLO module scheduler that is optimized for
  // extracting concurrency at the cost of extra memory: we extend the live
  // ranges of temporaries to allow ZKX runtime to schedule independent
  // operations in parallel on separate threads.
  bool zkx_cpu_enable_concurrency_optimized_scheduler = 307;

  // When set, ZKX:CPU will only generate code up to the specified ISA.
  // (It will not use newer ISAs.) Using the string format allows us to extend
  // the flag for more flexible control if necessary.
  string zkx_cpu_max_isa = 333;

  // The number of parts to split the LLVM module into before codegen. This
  // allows ZKX to compile all parts in parallel, and resolve kernel symbols
  // from different dynamic libraries.
  int32 zkx_cpu_parallel_codegen_split_count = 323;

  // A `prefer-vector-width` value that is passed to the LLVM backend. Default
  // value is `256` (AVX2 on x86 platforms).
  int32 zkx_cpu_prefer_vector_width = 308;

  // Do not lock collective cliques for each ZKX:GPU execution, and instead
  // use per-process cliques that are never unlocked. This disables deadlock
  // prevention mechanism in ZKX:GPU and should be used at your own risk. If
  // collective operations from concurrent executions are not correctly ordered
  // it may lead to deadlocks, crashes or will produce garbage.
  bool zkx_gpu_collectives_use_persistent_cliques = 354;

  // Path to directory with cuda/ptx tools and libraries.
  string zkx_gpu_cuda_data_dir = 61;

  // File to write autotune logs to. It will stored in txt format.
  string zkx_gpu_dump_autotune_logs_to = 292;

  // File to write autotune results to. It will be a binary file unless the name
  // ends with .txt or .textproto. Warning: The results are written at every
  // compilation, possibly multiple times per process. This only works on CUDA.
  string zkx_gpu_dump_autotune_results_to = 222;

  bool zkx_gpu_dump_autotuned_gemm_fusions = 232;

  // If true, every time an HLO module is run, we will dump an
  // HloUnoptimizedSnapshot (essentially, a serialized unoptimizedmodule plus
  // its inputs) to the --zkx_dump_to directory.
  bool zkx_gpu_dump_hlo_unoptimized_snapshots = 352;

  // Whether to dump llvm ir when compiling to ptx.
  bool zkx_gpu_dump_llvmir = 155;

  // Timeout to terminate on stuck rendezvous.
  int32 zkx_gpu_executable_terminate_timeout_seconds = 328;

  // Timeout to issue a warning on stuck rendezvous.
  int32 zkx_gpu_executable_warn_stuck_timeout_seconds = 327;

  // Dump FDO profiles in a binary format to a separate file.
  bool zkx_gpu_experimental_dump_fdo_profiles = 338;

  bool zkx_gpu_enable_highest_priority_async_stream = 216;

  // If enabled, uses the libnvptxcompiler library to compile PTX to cuBIN.
  bool zkx_gpu_enable_libnvptxcompiler = 269;

  // Overrides normal multi-threaded compilation setting to use this many
  // threads. Setting to 0 (the default value) means no enforcement.
  bool zkx_gpu_enable_llvm_module_compilation_parallelism = 268;

  // Enable NCCL communicator splitting.
  bool zkx_gpu_enable_nccl_comm_splitting = 272;

  // If enabled, uses the libnvjitlink library for PTX compilation and linking
  LibNvJitLinkMode zkx_gpu_libnvjitlink_mode = 343;

  // Specify the maximum number of channels(SMs) NCCL
  // will use for collective operations.
  int64 zkx_gpu_nccl_collective_max_nchannels = 273;

  // Set number of ranks per root rank for NCCL init.
  int64 zkx_gpu_nccl_init_max_rank_per_root_ratio = 277;

  // Specify the maximum number of channels(SMs) NCCL
  // will use for p2p operations.
  int64 zkx_gpu_nccl_p2p_max_nchannels = 274;

  // If true, NCCL errors will terminate the process.
  bool zkx_gpu_nccl_terminate_on_error = 301;

  // Timeout in seconds before terminating jobs that are stuck in a NCCL
  // Rendezvous. Negative value disables the timeout and will not terminate.
  int64 zkx_gpu_nccl_termination_timeout_seconds = 163;

  // If true, ZKX runtime will retain exclusive ownership of the GPU when
  // running a module, so there are no multi-thread conflicts on the GPU. This
  // can enable some optimizations that reduce the cost of resource management,
  // e.g., command buffer updates to ensure correctness when running in
  // multi-thread mode.
  bool zkx_gpu_require_exclusive_lock = 347;

  // It is usually preferable to not fallback to the driver; it can consume more
  // memory, or have bugs.
  bool zkx_gpu_unsafe_fallback_to_driver_on_ptxas_not_found = 138;

  // If true, ZKX will annotate instructions in the dumps with emitter code
  // location (source:line) annotations. This helps to identify the source of
  // the code that emits a particular instruction.
  bool zkx_annotate_with_emitter_loc = 358;

  // Instrument the computation to collect per-HLO cycle counts.
  bool zkx_hlo_profile = 9;

  // List of HLO passes to disable/enable. These names must exactly match the
  // pass names as specified by the HloPassInterface::name() method.
  //
  // At least one of zkx_disable_hlo_passes and zkx_enable_hlo_passes_only must
  // be empty.
  repeated string zkx_disable_hlo_passes = 30;
  repeated string zkx_enable_hlo_passes_only = 124;

  // Disables all HLO passes.  Notes that some passes are necessary for
  // correctness and the invariants that must be satisfied by "fully optimized"
  // HLO are different for different devices and may change over time.  The only
  // "guarantee", such as it is, is that if you compile ZKX and dump the
  // optimized HLO for some graph, you should be able to run it again on the
  // same device with the same build of ZKX.
  bool zkx_disable_all_hlo_passes = 104;

  // Numerical optimization level for the ZKX compiler backend; the specific
  // interpretation of this value is left to the backends.
  int32 zkx_backend_optimization_level = 31;

  // If true, in LLVM-based backends, emit !invariant.load metadata in
  // the generated IR.
  bool zkx_llvm_enable_invariant_load_metadata = 72;

  // Force the host platform to pretend that there are these many host
  // "devices".  All these devices are backed by the same threadpool. Defaults
  // to 1.
  //
  // Setting this to anything other than 1 can increase overhead from context
  // switching but we let the user override this behavior to help run tests on
  // the host that run models in parallel across multiple devices.
  int32 zkx_force_host_platform_device_count = 102;

  // If true, a set of expensive LLVM optimization passes will not be run.
  bool zkx_llvm_disable_expensive_passes = 73;

  // Enable fast math with eigen in the HLO evaluator.
  bool zkx_hlo_evaluator_use_fast_path = 106;

  //
  // BEGIN flags controlling dumping HLO modules for debugging.
  //
  // When dumping is enabled, HLO modules dumped at the very beginning and end
  // of compilation, and optionally also during the pass pipeline.
  //
  // In general, if you set one of these flags, we will try to infer reasonable
  // defaults for the others. For example:
  //
  //  * Setting --zkx_dump_to=/tmp/foo without specifying a format
  //    with --zkx_dump_hlo_as_* will turn on --zkx_dump_hlo_as_text.
  //
  //  * Setting --zkx_dump_hlo_as_text without specifying --zkx_dump_to will
  //    dump to stdout.
  //

  // Directory to dump into.
  string zkx_dump_to = 109;
  bool zkx_flags_reset = 364;

  // If specified, will only dump modules which match this regexp.
  string zkx_dump_hlo_module_re = 110;

  // If this flag is specified, will also dump HLO before and after passes that
  // match this regular expression. Set to .* to dump before/after all passes.
  string zkx_dump_hlo_pass_re = 111;

  // Specifies the format that HLO is dumped in. Multiple of these may be
  // specified.
  bool zkx_dump_hlo_as_text = 112;
  bool zkx_dump_hlo_as_proto = 113;
  bool zkx_dump_hlo_as_dot = 114;
  bool zkx_dump_hlo_as_url = 115;

  // Dump HLO graphs as an HTML (DOT -> SVG inlined in HTML)
  bool zkx_dump_hlo_as_html = 116;

  // Dump the visualization of the fusion progress.
  bool zkx_dump_fusion_visualization = 149;

  // If true, every time an HLO module is run, we will dump an HloSnapshot
  // (essentially, a serialized module plus its inputs) to the --zkx_dump_to
  // directory.
  bool zkx_dump_hlo_snapshots = 118;

  // Include a timestamp in the dumped filenames.
  bool zkx_dump_include_timestamp = 131;

  // Max number of hlo module dumps in a directory. Set to < 0 for unbounded.
  int32 zkx_dump_max_hlo_modules = 132;

  // Dump HloModuleMetadata as a text proto for each HLO module.
  bool zkx_dump_module_metadata = 144;

  // GZip-compress protos dumped via --zkx_dump_hlo_as_proto.
  bool zkx_dump_compress_protos = 151;

  // Dump HLO in long text format. Ignored unless zkx_dump_hlo_as_text is true.
  bool zkx_dump_hlo_as_long_text = 164;

  //
  // END flags controlling dumping HLO modules.
  //

  // Whether to dump mlir using pretty print form.
  bool zkx_dump_enable_mlir_pretty_form = 185;

  // Enable HLO dumping. If this is disabled, no HLO modules will be dumped.
  bool zkx_enable_dumping = 253;

  // Disable dumping metadata in HLO dumps.
  bool zkx_dump_disable_metadata = 153;

  // If this flag is specified, will only dump HLO before and after passes in
  // the pass pipeline that matches this regular expression. Default empty value
  // enables dumping in all pipelines.
  string zkx_dump_hlo_pipeline_re = 154;

  // Per-heap size constraint. New heaps will be created if per-heap max size is
  // reached.
  int32 zkx_multiheap_size_constraint_per_heap = 142;

  // If true, large constants will be printed out when dumping HLOs.
  bool zkx_dump_large_constants = 290;

  // This flag is used for controlling HLO dumping and NVTX marker. If turned
  // on, both HLO dumping and NVTX marker will use syntactic sugar wrappers
  // as op names, while the actual op names will be shown if turned off.
  //
  // Here is an example HLO excerpt with the flag off:
  //
  //   async_computation {
  //    param_0 = f32[1,4,8]{1,0,2} parameter(0)
  //    ROOT all-to-all.3.1 = f32[1,4,8]{1,0,2} all-to-all(param_0),
  //                          replica_groups={{0,1,2,3,4,5,6,7}}, dimensions={2}
  //   }
  //  ...
  //
  //  all-to-all-start =
  //    ((f32[1,4,8]{1,0,2}), f32[1,4,8]{1,0,2}) async-start(bitcast.24.0),
  //    calls=async_computation, backend_config={...}
  //  all-to-all-done = f32[1,4,8]{1,0,2} async-done(all-to-all-start)
  //
  // and with the flag on:
  //
  //  all-to-all-start = ((f32[1,4,8]{1,0,2}), f32[1,4,8]{1,0,2})
  //                     all-to-all-start(bitcast.24.0),
  //                     replica_groups={{0,1,2,3,4,5,6,7}}, dimensions={2},
  //                     backend_config={...}
  //  all-to-all-done = f32[1,4,8]{1,0,2} all-to-all-done(all-to-all-start)
  bool zkx_syntax_sugar_async_ops = 315;

  bool zkx_pjrt_allow_auto_layout_in_hlo = 344;

  // Extra options to pass to the compilation backend (e.g. LLVM); specific
  // interpretation of these values is left to the backend.
  map<string, string> zkx_backend_extra_options = 500;
}

message ShardableValueUpdatePairProto {
  int64 input_parameter_number = 1;
  repeated int64 parameter_shape_index = 2;
  repeated int64 output_shape_index = 3;
}

// These settings control how ZKX compiles and/or runs code.  Not all settings
// will have an effect on every platform.
//
// When adding new fields, keep in mind that boolean fields default to false.
// Next id: 27.
message ExecutionOptions {
  // This optional field's layout is used as a hint when storing the output of
  // this computation.  Subsequent transfers of this output array to the client
  // may be faster when using this layout.
  //
  // We use a Shape here to accommodate computations that return a tuple.
  ShapeProto shape_with_output_layout = 2;

  // Used to seed random-number generators used in this computation.  If this is
  // 0, we generate a seed ourselves.
  //
  // Changing the seed unnecessarily forces a recompilation.
  uint64 seed = 3;

  DebugOptions debug_options = 4;

  // This optional field specifies a particular set of devices to run the
  // computation on. The computation will be partitioned across these devices.
  // If not provided, the default device will be chosen.
  repeated DeviceHandle device_handles = 5;

  // Number of replicas of the computation to run. If zero, uses the default
  // number of replicas for the ZKX service.
  int32 num_replicas = 6;

  // This optional field specifies the device assignment if known at compile
  // time.
  DeviceAssignmentProto device_assignment = 7;

  // Alias input and output buffers for parameters that are passed-through ZKX
  // modules without being changed.
  bool alias_passthrough_params = 8;

  // Number of partitions of the computation to run (model parallelism).
  // If zero, uses the default number of partitions for the ZKX service.
  int32 num_partitions = 9;

  // Used to identify a set of programs that should be launch together.
  int32 launch_id = 10;

  // Indicates whether to use SPMD (true) or MPMD (false) partitioning when
  // num_partitions > 1 and ZKX is requested to partition the input program.
  bool use_spmd_partitioning = 11;

  // Whether to automatically generate ZKX shardings for SPMD partitioner.
  bool use_auto_spmd_partitioning = 15;

  // Device mesh shape used to create the sharding search space when
  // use_auto_spmd_partitioning=true.
  repeated int64 auto_spmd_partitioning_mesh_shape = 16;

  // Device mesh ids compatible with the above mesh_shape used when
  // use_auto_spmd_partitioning=true.
  repeated int64 auto_spmd_partitioning_mesh_ids = 17;

  // The amount of effort to spend on optimizing for minimizing program
  // execution time, as a value in [-1.0, +1.0]. The baseline is 0.0, which
  // strongly prioritizes execution time at the cost of longer compile times,
  // suitable for production workloads. A value of -0.5 would be appropriate for
  // research use cases that prefer faster compilations to iterate more quickly.
  // Positive values, on the other hand, might enable costly optimizations that
  // are off by default.
  float exec_time_optimization_effort = 25;

  // The amount of effort to spend on making the program fit in memory (where
  // "fit in memory" here has a backend-dependent meaning), as a value in
  // [-1.0,+1.0]. The baseline is 0.0, which expends significant effort on
  // attempting to make the program fit. A value of -1.0 would be appropriate
  // for use cases that wish to spend minimal effort here and fail as quickly as
  // possible instead. Positive values, on the other hand, might enable costly
  // algorithms to reduce memory usage that are off by default.
  float memory_fitting_effort = 26;

  // If set, deduplicate hlo into function calls to reduce binary size. Only
  // works on TPU.
  bool deduplicate_hlo = 12;

  reserved 13;  // Was broadcast_replicated_parameters_via_collectives

  // Allows sharding propagation to propagate to the parameters. This changes
  // the input shape of the computation (which is undesirable), but it can be
  // used to allow to run partial compilation to determine what would be the
  // input sharding of a computation if ZKX would be allowed to propagate the
  // sharding which can be used by higher level framework as a way to query
  // intermediate sharding of operations when multiple computation would be
  // chained and merged together.
  // This is a vector of bool, because the user can control which parameters can
  // have the sharding substituted. If only one boolean value is passed in the
  // vector that is interpreted as the value to be applied for every parameter.
  repeated bool allow_spmd_sharding_propagation_to_parameters = 23;

  // Allows sharding propagation to propagate to the outputs. This changes the
  // output shape of the computation (which is undesirable), but it can be used
  // to allow to run partial compilation to determine what would be the output
  // sharding of a computation if ZKX would be allowed to propagate the sharding
  // which can be used by higher level framework as a way to query intermediate
  // sharding of operations when multiple computation would be chained and
  // merged together.
  // This is a vector of bool, because the user can control (if the output of
  // the computation is a tuple) which elements of the tuple can have the
  // sharding substituted and which don't. If only one boolean value is passed
  // in the vector that's interpreted as the value to be applied for every
  // single element of the output tuple. One value per element of the tuple
  // means that each value is attached to one of the output elements.
  repeated bool allow_spmd_sharding_propagation_to_output = 14;

  // Whether to broadcast args across all replicas. One entry per arg.
  repeated bool param_requires_broadcast_via_collectives = 18;

  // If enabled, the compiler may generate sharding and unsharding programs as
  // separate HLO modules, and modify the main program's input and output to
  // be sharded.
  bool allow_separate_sharding_programs = 19;

  // The list of input/output pairs in the main program that could be sharded.
  repeated ShardableValueUpdatePairProto shardable_value_update_pairs = 20;

  // Profiling data for feedback directed optimizations. Note that this is not
  // the only way to feed FDO data into the compiler and individual backends
  // may choose to get FDO data by other means.
  bytes fdo_profile = 21;

  // Amount of device memory available for the executable to use.
  int64 device_memory_size = 22;

  // Use Shardy, a new partitioner, to replace the existing
  // ShardingPropagation and SpmdPartitioner. See go/xla-sdy-pipeline for
  // details.
  bool use_shardy_partitioner = 24;
}

// Serialization of HloModuleConfig. See the C++ class definition for
// descriptions of each field.
// There are no guarantees of backwards or forwards compatibility.
// Next id: 37.
message HloModuleConfigProto {
  enum FusionConfigCollection {
    OFF = 0;       // Do not collect configuration.
    PER_EDGE = 1;  // Collect per-edge configuration.
    PER_NODE = 2;  // Collect per-node configuration.
  }

  message BoolList {
    repeated bool vals = 1;
  }
  message Int64List {
    repeated int64 vals = 1;
  }
  message Int64ListList {
    repeated Int64List lists = 1;
  }

  ProgramShapeProto entry_computation_layout = 1;
  uint64 seed = 2;
  int32 launch_id = 3;
  int64 replica_count = 4;
  int64 num_partitions = 5;
  repeated bool param_requires_broadcast_via_collectives = 6;
  bool use_spmd_partitioning = 7;
  bool use_auto_spmd_partitioning = 8;
  repeated int64 auto_spmd_partitioning_mesh_shape = 9;
  repeated int64 auto_spmd_partitioning_mesh_ids = 10;
  float exec_time_optimization_effort = 11;
  float memory_fitting_effort = 12;
  bool deduplicate_hlo = 13;
  int64 intra_op_parallelism_threads = 14;
  string device_type = 15;

  DebugOptions debug_options = 16;
  DeviceAssignmentProto static_device_assignment = 17;
  // The original device assignment before being changed by a simulator.
  // Simulators, like HybridSim, may change the device assignment to a smaller
  // topology, to make simulation easier.
  DeviceAssignmentProto pre_simulation_device_assignment = 18;
  bool allow_separate_sharding_programs = 19;
  repeated ShardableValueUpdatePairProto shardable_value_update_pairs = 20;
  bool alias_passthrough_params = 21;
  bool content_aware_computation_sorting = 22;
  FusionConfigCollection fusion_config_collection = 23;

  repeated BoolList fusion_config = 24;
  map<string, Int64List> dot_config = 25;
  repeated Int64ListList layout_config = 26;

  repeated uint64 memory_space_assignment_config = 27;
  repeated BoolList phase_ordering_config = 28;
  int32 phase_index = 29;
  repeated bool allow_spmd_sharding_propagation_to_parameters = 30;
  repeated bool allow_spmd_sharding_propagation_to_output = 31;
  map<string, int64> analysis_allowance_map = 32;
  bytes fdo_profile = 33;
  int64 device_memory_size = 34;
  bool use_shardy_partitioner = 35;
  ShardingConfigProto sharding_config = 36;
}

message HloModuleProtoWithConfig {
  HloModuleProto hlo_module = 1;
  HloModuleConfigProto config = 2;
}

// Message that captures sharding configuration of an HLO op.
message NodeShardingConfigProto {
  OpSharding sharding = 1;                     // For non-tuples.
  repeated NodeShardingConfigProto nodes = 2;  // For tuples.
}

// Message that captures sharding configuration of an HLO module.
message ShardingConfigProto {
  // Configuration for each HLO instruction.
  repeated NodeShardingConfigProto nodes = 1;
}
