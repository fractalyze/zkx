syntax = "proto3";

package zkx.gpu;

// Backend configs for ZKX:GPU.
//
// These are metadata that the GPU backend attaches to HloInstructions and later
// uses during e.g. codegen.
//
// GpuBackendConfig serves as a parent config for all backend configs so
// configs won't overwrite each other. Any new backend config proto
// should be added to and used in GpuBackendConfig.
//
// Remember that proto3 doesn't give clients a way to tell the difference
// between a field not being present and a field having the default value.
// Choose your defaults carefully.
//
// No guarantee is made about the stability of these protos.
//
// See HloInstruction::backend_config() for more info.

// Backend config for cost model estimates.
message ReificationCost {
  // Total execution time of the reified op.
  double end_to_end_cycles = 1;

  // Estimated overall kernel execution in microseconds.
  //
  // GPU Cost Model estimates compute and memory access time separately. Exec
  // time is a combined metric of the two.
  double exec_time_us = 2;

  // Estimate for compute time in microseconds.
  double compute_time_us = 3;

  // Estimate for memory access (read+write) time in microseconds.
  double memory_access_time_us = 4;
}

// Backend config for a custom fusion (pre-compiled device kernel implementing a
// fusion computation).
message CustomFusionConfig {
  string name = 1;

  // When a custom fusion has multiple kernels, this field specifies which
  // kernel to use. Default value is to select the first kernel, i.e.
  // kernel_index = 0.
  int32 kernel_index = 2;
}

// Block-level parameters for a fusion.
message BlockLevelFusionConfig {
  // The output tile sizes of the associated instruction. The length of this
  // field is expected to be the rank of the output shape.
  repeated int64 output_tile_sizes = 1;

  // The number of warps to use for the kernel.
  int64 num_warps = 2;
}

message FusionBackendConfig {
  // kLoop, kInput, or kOutput (from HloInstruction::FusionKind), or your own
  // custom string.
  //
  // Don't put "kCustom" in here -- just put a string describing the custom
  // fusion, like "__triton_gemm".
  //
  // This is somewhat redundant with HloInstruction::fusion_kind().  We need it
  // here because LMHLO does not have the concept of a fusion kind, and we use
  // this same backend-config proto for both HLO and LMHLO.
  string kind = 1;

  // Only valid when kind == "__triton_gemm".  Even then it's optional: If not
  // present, we use the default Triton config.
  // TODO(chokobole): Uncomment this. Dependency: TritonGemmKey
  // AutotuneResult.TritonGemmKey triton_gemm_config = 2;

  // Only valid when kind == "__triton" for now. Code generation of such
  // fusions will fail if this field is not set.
  BlockLevelFusionConfig block_level_fusion_config = 6;

  // Only valid when kind == "__custom_fusion".
  CustomFusionConfig custom_fusion_config = 4;

  // Cost model prediction.
  ReificationCost reification_cost = 3;
}

// Backend config for a general custom call instruction, e.g. ZKX FFI.
message CustomCallBackendConfig {
  // Generic configurations that can be parsed by ZKX.
  oneof raw_backend_config_oneof {
    // An opaque ASCII string could be parsed by the compiler.
    string opaque = 1;
    // Attributes parsed by ZKX FFI.
    string attributes = 2;
  }
}

// Generic backend config for ZKX:GPU
// Next-Id: 12
message GpuBackendConfig {
  // Specifies which operation queue the current instruction will run on.
  // A backend may have multiple operation queues to run instructions
  // concurrently, use this to signal the backend which queue to dispatch to.
  // The backend should keep a mapping of
  // operation_queue_id->actual_hardware_queue_id if runtime will create
  // different IDs.
  int64 operation_queue_id = 1;

  // Specifies which operation queues to await for data when running with
  // multiple operation queues.
  repeated int64 wait_on_operation_queues = 2;

  oneof backend_config {
    FusionBackendConfig fusion_backend_config = 7;

    CustomCallBackendConfig custom_call_backend_config = 11;
  }

  // This attribute instructs the latency-hiding scheduler to
  // schedule this particular instruction to the earliest position.
  // Note that setting this to true will make this instruction scheduled
  // at the very beginning of the parent computation before
  // every other nodes.
  // An example use case would be deciding to schedule between collective
  // or an async compute. LHS might put either one at the first place
  // depending on the cost, but it'd be more beneficial if the collective
  // is always scheduled first as it's not SM-heavy.
  // In this case we can use this flag to enforce the ordering.
  bool force_earliest_schedule = 10;
}
